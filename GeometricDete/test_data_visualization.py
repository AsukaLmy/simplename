#!/usr/bin/env python3
"""
æ•°æ®è½½å…¥è¿‡ç¨‹å¯è§†åŒ–æµ‹è¯•è„šæœ¬
æ£€æŸ¥Stage2æ•°æ®é›†çš„ç‰¹å¾æå–æ˜¯å¦æ­£ç¡®
"""

import os
import sys

# è§£å†³OpenMPåº“å†²çªé—®é¢˜
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

import torch
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from matplotlib.patches import Rectangle
import cv2
from PIL import Image, ImageDraw, ImageFont

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from datasets.stage2_dataset import BasicStage2Dataset
from configs.stage2_config import Stage2Config


def visualize_interaction_pair(sample, dataset, idx, save_dir="./visualization_output"):
    """
    å¯è§†åŒ–å•ä¸ªäº¤äº’å¯¹
    
    Args:
        sample: æ•°æ®é›†æ ·æœ¬
        dataset: æ•°æ®é›†å¯¹è±¡
        idx: æ ·æœ¬ç´¢å¼•
        save_dir: ä¿å­˜ç›®å½•
    """
    os.makedirs(save_dir, exist_ok=True)
    
    # æå–ä¿¡æ¯
    features = sample['features'].numpy()
    stage2_label = sample['stage2_label'].item()
    frame_id = sample['frame_id']
    original_interaction = sample['original_interaction']
    person_A_id = sample['person_A_id']
    person_B_id = sample['person_B_id']
    
    # ä»æ•°æ®é›†å†…éƒ¨è·å–æ›´å¤šä¿¡æ¯
    raw_sample = dataset.samples[idx]
    person_A_box = raw_sample['person_A_box']  # [x, y, w, h]
    person_B_box = raw_sample['person_B_box']  # [x, y, w, h]
    scene_name = raw_sample['scene_name']
    image_name = raw_sample['image_name']
    
    # æ ‡ç­¾æ˜ å°„
    label_names = ['Walking Together', 'Standing Together', 'Sitting Together']
    label_name = label_names[stage2_label] if stage2_label < len(label_names) else f'Unknown_{stage2_label}'
    
    # ç‰¹å¾åˆ†è§£ (å‡è®¾æ˜¯72ç»´ï¼š7å‡ ä½•+64HoG+1åœºæ™¯ä¸Šä¸‹æ–‡)
    feature_dim = len(features)
    if feature_dim >= 72:
        geometric_features = features[:7]
        hog_features = features[7:71]
        scene_context = features[71]
    elif feature_dim >= 8:
        geometric_features = features[:7]
        hog_features = features[7:-1] if feature_dim > 8 else features[7:8]
        scene_context = features[-1]
    else:
        geometric_features = features
        hog_features = np.array([])
        scene_context = 0.0
    
    print(f"\nğŸ“Š äº¤äº’å¯¹ä¿¡æ¯:")
    print(f"  åœºæ™¯: {scene_name}")
    print(f"  å›¾åƒ: {image_name}")
    print(f"  å¸§ID: {frame_id}")
    print(f"  äººå‘˜A ID: {person_A_id}, äººå‘˜B ID: {person_B_id}")
    print(f"  åŸå§‹äº¤äº’: {original_interaction}")
    print(f"  æ ‡ç­¾: {label_name} (ID: {stage2_label})")
    print(f"  ç‰¹å¾ç»´åº¦: {feature_dim}")
    
    print(f"\nğŸ”¢ ç‰¹å¾ç»Ÿè®¡:")
    if len(geometric_features) > 0:
        print(f"  å‡ ä½•ç‰¹å¾ ({len(geometric_features)}ç»´): mean={geometric_features.mean():.4f}, std={geometric_features.std():.4f}")
        if len(geometric_features) >= 7:
            print(f"    - æ°´å¹³é—´è·(å½’ä¸€åŒ–): {geometric_features[0]:.4f}")
            print(f"    - é«˜åº¦æ¯”: {geometric_features[1]:.4f}") 
            print(f"    - åœ°é¢è·ç¦»(å½’ä¸€åŒ–): {geometric_features[2]:.4f}")
            print(f"    - å‚ç›´é‡å : {geometric_features[3]:.4f}")
            print(f"    - é¢ç§¯æ¯”: {geometric_features[4]:.4f}")
            print(f"    - ä¸­å¿ƒè·ç¦»(å½’ä¸€åŒ–): {geometric_features[5]:.4f}")
            print(f"    - å‚ç›´è·ç¦»æ¯”: {geometric_features[6]:.4f}")
    
    if len(hog_features) > 0:
        print(f"  HoGç‰¹å¾ ({len(hog_features)}ç»´): mean={hog_features.mean():.4f}, std={hog_features.std():.4f}")
    
    print(f"  åœºæ™¯ä¸Šä¸‹æ–‡: {scene_context:.4f}")
    
    # è¾¹ç•Œæ¡†ä¿¡æ¯
    print(f"\nğŸ“¦ è¾¹ç•Œæ¡†ä¿¡æ¯:")
    print(f"  äººå‘˜A: {person_A_box} (x,y,w,h)")
    print(f"  äººå‘˜B: {person_B_box} (x,y,w,h)")
    
    # å…¨æ™¯å›¾åƒè¾¹ç•Œæ£€æŸ¥
    center_A_x = person_A_box[0] + person_A_box[2] / 2
    center_B_x = person_B_box[0] + person_B_box[2] / 2
    dx_direct = abs(center_A_x - center_B_x)
    dx_wraparound = 3760 - dx_direct
    print(f"  æ°´å¹³è·ç¦»: ç›´æ¥={dx_direct:.1f}, ç¯ç»•={dx_wraparound:.1f}, å®é™…ä½¿ç”¨={'ç¯ç»•' if dx_wraparound < dx_direct else 'ç›´æ¥'}")
    
    # æ£€æŸ¥æ˜¯å¦å¯èƒ½è·¨è¶Šè¾¹ç•Œ
    if (center_A_x < 500 and center_B_x > 3260) or (center_A_x > 3260 and center_B_x < 500):
        print(f"  âš ï¸  æ£€æµ‹åˆ°å…¨æ™¯è¾¹ç•Œè·¨è¶Šæƒ…å†µï¼")
    
    # å°è¯•è·å–å›¾åƒè·¯å¾„å¹¶å¯è§†åŒ–
    scene_info = dataset.scene_data.get(frame_id, {})
    image_path = scene_info.get('image_path')
    
    if image_path and os.path.exists(image_path):
        visualize_on_image(sample, raw_sample, image_path, save_dir)
    else:
        print(f"âš ï¸  å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨æˆ–è·¯å¾„æ— æ•ˆ: {image_path}")
    
    return sample


def visualize_on_image(sample, raw_sample, image_path, save_dir):
    """
    åœ¨åŸå›¾ä¸Šå¯è§†åŒ–äº¤äº’å¯¹
    
    Args:
        sample: å¤„ç†åçš„æ ·æœ¬
        raw_sample: åŸå§‹æ ·æœ¬æ•°æ® 
        image_path: å›¾åƒè·¯å¾„
        save_dir: ä¿å­˜ç›®å½•
    """
    try:
        # è¯»å–å›¾åƒ
        image = cv2.imread(image_path)
        if image is None:
            print(f"âŒ æ— æ³•è¯»å–å›¾åƒ: {image_path}")
            return
        
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # åˆ›å»ºå›¾åƒå‰¯æœ¬ç”¨äºç»˜åˆ¶
        img_with_annotations = image.copy()
        
        # è®¾ç½®matplotlib
        plt.figure(figsize=(15, 10))
        plt.imshow(img_with_annotations)
        
        # è·å–è¾¹ç•Œæ¡†ä¿¡æ¯ (æ ¼å¼: [x, y, w, h])
        person_A_box = raw_sample['person_A_box']
        person_B_box = raw_sample['person_B_box']
        
        # ç»˜åˆ¶Person Aè¾¹ç•Œæ¡† (è“è‰²)
        rect1 = Rectangle((person_A_box[0], person_A_box[1]), 
                         person_A_box[2], person_A_box[3],
                         linewidth=3, edgecolor='blue', facecolor='none')
        plt.gca().add_patch(rect1)
        plt.text(person_A_box[0], person_A_box[1] - 10, 
                f'Person A (ID: {raw_sample["person_A_id"]})', 
                color='blue', fontsize=12, fontweight='bold',
                bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))
        
        # ç»˜åˆ¶Person Bè¾¹ç•Œæ¡† (çº¢è‰²)
        rect2 = Rectangle((person_B_box[0], person_B_box[1]), 
                         person_B_box[2], person_B_box[3],
                         linewidth=3, edgecolor='red', facecolor='none')
        plt.gca().add_patch(rect2)
        plt.text(person_B_box[0], person_B_box[1] - 10, 
                f'Person B (ID: {raw_sample["person_B_id"]})', 
                color='red', fontsize=12, fontweight='bold',
                bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))
        
        # ç»˜åˆ¶è¿æ¥çº¿
        center1 = (person_A_box[0] + person_A_box[2] // 2, 
                  person_A_box[1] + person_A_box[3] // 2)
        center2 = (person_B_box[0] + person_B_box[2] // 2, 
                  person_B_box[1] + person_B_box[3] // 2)
        
        plt.plot([center1[0], center2[0]], [center1[1], center2[1]], 
                'g--', linewidth=3, alpha=0.8, label='äº¤äº’è¿çº¿')
        
        # æ·»åŠ æ ‡é¢˜å’Œä¿¡æ¯
        stage2_label = sample['stage2_label'].item()
        label_names = ['Walking Together', 'Standing Together', 'Sitting Together']
        label_name = label_names[stage2_label] if stage2_label < len(label_names) else f'Unknown_{stage2_label}'
        
        plt.title(f'Stage2äº¤äº’å¯¹å¯è§†åŒ–\n'
                 f'åœºæ™¯: {raw_sample["scene_name"]} | å›¾åƒ: {raw_sample["image_name"]}\n'
                 f'åŸå§‹äº¤äº’: {sample["original_interaction"]} | æ ‡ç­¾: {label_name} (ID: {stage2_label})', 
                 fontsize=14, pad=20)
        
        plt.axis('off')
        plt.legend(loc='upper right')
        
        # ä¿å­˜å›¾åƒ
        output_filename = f"{raw_sample['scene_name']}_{raw_sample['image_name']}_{raw_sample['person_A_id']}_{raw_sample['person_B_id']}.png"
        output_filename = output_filename.replace('.jpg', '').replace('.png', '') + '.png'
        output_path = os.path.join(save_dir, output_filename)
        plt.savefig(output_path, dpi=150, bbox_inches='tight', facecolor='white')
        plt.close()
        
        print(f"âœ… å¯è§†åŒ–å›¾åƒå·²ä¿å­˜: {output_path}")
        
    except Exception as e:
        print(f"âŒ å¯è§†åŒ–è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


def plot_feature_distribution(samples, save_dir="./visualization_output"):
    """
    ç»˜åˆ¶ç‰¹å¾åˆ†å¸ƒå›¾
    
    Args:
        samples: æ ·æœ¬åˆ—è¡¨
        save_dir: ä¿å­˜ç›®å½•
    """
    if not samples:
        return
    
    # æ”¶é›†æ‰€æœ‰ç‰¹å¾å’Œæ ‡ç­¾
    all_features = []
    all_labels = []
    
    for sample in samples:
        features = sample['features'].numpy()
        label = sample['stage2_label'].item()
        all_features.append(features)
        all_labels.append(label)
    
    all_features = np.array(all_features)
    all_labels = np.array(all_labels)
    
    # ç»˜åˆ¶ç‰¹å¾åˆ†å¸ƒ
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # å‡ ä½•ç‰¹å¾åˆ†å¸ƒ
    geometric_features = all_features[:, :7]
    axes[0, 0].hist(geometric_features[:, 0], bins=20, alpha=0.7, label='Distance')
    axes[0, 0].set_title('å‡ ä½•ç‰¹å¾åˆ†å¸ƒ - è·ç¦»')
    axes[0, 0].set_xlabel('Distance')
    axes[0, 0].set_ylabel('Frequency')
    
    # HoGç‰¹å¾åˆ†å¸ƒ
    if all_features.shape[1] > 7:
        hog_features = all_features[:, 7:71] if all_features.shape[1] >= 71 else all_features[:, 7:]
        hog_mean = np.mean(hog_features, axis=1)
        axes[0, 1].hist(hog_mean, bins=20, alpha=0.7, color='orange')
        axes[0, 1].set_title('HoGç‰¹å¾åˆ†å¸ƒ - å¹³å‡å€¼')
        axes[0, 1].set_xlabel('HoG Mean')
        axes[0, 1].set_ylabel('Frequency')
    
    # æ ‡ç­¾åˆ†å¸ƒ
    label_names = ['Walking Together', 'Standing Together', 'Sitting Together']
    unique_labels, counts = np.unique(all_labels, return_counts=True)
    axes[1, 0].bar([label_names[i] if i < len(label_names) else f'Class_{i}' for i in unique_labels], 
                  counts, alpha=0.7, color=['blue', 'green', 'red'][:len(unique_labels)])
    axes[1, 0].set_title('ç±»åˆ«åˆ†å¸ƒ')
    axes[1, 0].set_ylabel('Count')
    axes[1, 0].tick_params(axis='x', rotation=45)
    
    # ç‰¹å¾ç»´åº¦ç»Ÿè®¡
    feature_dims = [len(features) for features in all_features]
    axes[1, 1].hist(feature_dims, bins=10, alpha=0.7, color='purple')
    axes[1, 1].set_title('ç‰¹å¾ç»´åº¦åˆ†å¸ƒ')
    axes[1, 1].set_xlabel('Feature Dimension')
    axes[1, 1].set_ylabel('Count')
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾åƒ
    output_path = os.path.join(save_dir, 'feature_distribution.png')
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… ç‰¹å¾åˆ†å¸ƒå›¾å·²ä¿å­˜: {output_path}")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ” å¼€å§‹æ•°æ®è½½å…¥è¿‡ç¨‹å¯è§†åŒ–æµ‹è¯•...")
    
    # åˆ›å»ºé…ç½®
    config = Stage2Config(
        data_path="../dataset",  # æ ¹æ®å®é™…è·¯å¾„è°ƒæ•´
        batch_size=1,
        num_workers=0,  # è®¾ä¸º0ä¾¿äºè°ƒè¯•
        frame_interval=10,  # æ¯10å¸§é‡‡æ ·
        temporal_mode='none',  # Basicæ¨¡å¼
        use_geometric=True,
        use_hog=True,
        use_scene_context=True
    )
    
    print(f"ğŸ“‹ é…ç½®ä¿¡æ¯:")
    print(f"  æ•°æ®è·¯å¾„: {config.data_path}")
    print(f"  é‡‡æ ·é—´éš”: æ¯{config.frame_interval}å¸§")
    print(f"  ç‰¹å¾é…ç½®: å‡ ä½•={config.use_geometric}, HoG={config.use_hog}, åœºæ™¯={config.use_scene_context}")
    print(f"  è¾“å…¥ç»´åº¦: {config.get_input_dim()}")
    
    try:
        # åˆ›å»ºæ•°æ®é›†
        print(f"\nğŸ“‚ åˆ›å»ºè®­ç»ƒæ•°æ®é›†...")
        train_dataset = BasicStage2Dataset(
            data_path=config.data_path,
            split='train',
            use_geometric=config.use_geometric,
            use_hog=config.use_hog,
            use_scene_context=config.use_scene_context,
            frame_interval=config.frame_interval,
            use_oversampling=False  # æµ‹è¯•æ—¶ä¸ä½¿ç”¨è¿‡é‡‡æ ·
        )
        
        print(f"âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ!")
        print(f"  è®­ç»ƒé›†å¤§å°: {len(train_dataset)}")
        
        # å¯è§†åŒ–å‰10ä¸ªæ ·æœ¬
        print(f"\nğŸ¨ å¼€å§‹å¯è§†åŒ–å‰10ä¸ªäº¤äº’å¯¹...")
        samples_to_visualize = []
        
        for i in range(min(10, len(train_dataset))):
            print(f"\n{'='*50}")
            print(f"å¤„ç†ç¬¬ {i+1} ä¸ªäº¤äº’å¯¹:")
            
            try:
                sample = train_dataset[i]
                samples_to_visualize.append(sample)
                visualize_interaction_pair(sample, train_dataset, i)
                
            except Exception as e:
                print(f"âŒ å¤„ç†ç¬¬ {i+1} ä¸ªæ ·æœ¬æ—¶å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
                continue
        
        # ç»˜åˆ¶ç‰¹å¾åˆ†å¸ƒ
        if samples_to_visualize:
            print(f"\nğŸ“ˆ ç»˜åˆ¶ç‰¹å¾åˆ†å¸ƒå›¾...")
            plot_feature_distribution(samples_to_visualize)
        
        print(f"\nâœ… å¯è§†åŒ–æµ‹è¯•å®Œæˆ!")
        print(f"  æˆåŠŸå¤„ç†æ ·æœ¬æ•°: {len(samples_to_visualize)}")
        print(f"  å¯è§†åŒ–ç»“æœä¿å­˜åœ¨: ./visualization_output/")
        
    except FileNotFoundError as e:
        print(f"âŒ æ•°æ®è·¯å¾„é”™è¯¯: {e}")
        print("è¯·æ£€æŸ¥config.data_pathæ˜¯å¦æŒ‡å‘æ­£ç¡®çš„æ•°æ®é›†ç›®å½•")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()