# Dual-Person Feature Fusion Architecture with Downsampling

## ğŸ¯ æ¦‚è¿°

è¿™æ˜¯å¯¹åŸå§‹ä¸¤é˜¶æ®µäººç¾¤äº¤äº’è¯†åˆ«ç½‘ç»œçš„é‡è¦æ”¹è¿›ï¼Œè§£å†³äº†**äººç¾¤èšé›†åœºæ™¯ä¸‹ç‰¹å¾æå–ä¸ç²¾ç¡®**çš„å…³é”®é—®é¢˜ã€‚

### åŸå§‹æ¶æ„çš„é—®é¢˜
- âŒ è£å‰ªåŒ…å«ä¸¤äººçš„å¤§åŒºåŸŸ â†’ èƒŒæ™¯äººå‘˜å¹²æ‰°
- âŒ æ··åˆçš„åŒºåŸŸç‰¹å¾ â†’ éš¾ä»¥åŒºåˆ†ç›®æ ‡äººå‘˜
- âŒ äººç¾¤åœºæ™¯æ€§èƒ½ä¸‹é™ â†’ è¯¯æ£€ç‡é«˜

### åŒäººèåˆæ¶æ„çš„è§£å†³æ–¹æ¡ˆ
- âœ… ç‹¬ç«‹è£å‰ªæ¯ä¸ªäºº â†’ ç²¾ç¡®çš„ä¸ªä½“ç‰¹å¾
- âœ… å¤šç§èåˆç­–ç•¥ â†’ çµæ´»çš„ç‰¹å¾ç»„åˆ
- âœ… äººç¾¤åœºæ™¯ä¼˜åŒ– â†’ å‡å°‘èƒŒæ™¯å¹²æ‰°

## ğŸ—ï¸ æ¶æ„å¯¹æ¯”

### åŸå§‹æ¶æ„
```
åŒ…å«ä¸¤äººçš„å¤§åŒºåŸŸ [HÃ—WÃ—3] â†’ MobileNet â†’ GAP â†’ [1280] â†’ åˆ†ç±»å™¨
```

### åŒäººèåˆæ¶æ„
```
Person A [224Ã—224Ã—3] â†’ MobileNet â†’ [1280] â†˜
                                              â†’ Fusion â†’ [èåˆç‰¹å¾] â†’ åˆ†ç±»å™¨
Person B [224Ã—224Ã—3] â†’ MobileNet â†’ [1280] â†—
```

## ğŸ“ æ–‡ä»¶ç»“æ„

```
twostage_training/
â”œâ”€â”€ dual_person_downsampling_dataset.py      # åŒäººä¸‹é‡‡æ ·æ•°æ®åŠ è½½å™¨
â”œâ”€â”€ train_dual_person_stage1_downsampling.py # Stage1è®­ç»ƒï¼ˆäºŒåˆ†ç±»ï¼‰
â”œâ”€â”€ train_dual_person_stage2_downsampling.py # Stage2è®­ç»ƒï¼ˆå¤šåˆ†ç±»ï¼‰
â”œâ”€â”€ test_dual_person_downsampling.py         # æµ‹è¯•è„šæœ¬
â””â”€â”€ DUAL_PERSON_ARCHITECTURE_GUIDE.md        # æœ¬æŒ‡å—
```

## ğŸš€ ç‰¹å¾èåˆæ–¹æ³•

### 1. Concatenation (æ‹¼æ¥)
```python
fused = [feature_A, feature_B]  # [2560ç»´]
```
- **ä¼˜åŠ¿**: ä¿ç•™æ‰€æœ‰ä¿¡æ¯
- **åŠ£åŠ¿**: å‚æ•°ç¿»å€
- **é€‚ç”¨**: æ•°æ®å……è¶³æ—¶

### 2. Addition (ç›¸åŠ )
```python
fused = feature_A + feature_B  # [1280ç»´]
```
- **ä¼˜åŠ¿**: å‚æ•°å°‘ï¼Œå¯¹ç§°æ€§å¥½
- **åŠ£åŠ¿**: å¯èƒ½ä¸¢å¤±å·®å¼‚ä¿¡æ¯
- **é€‚ç”¨**: ç›¸ä¼¼è¡Œä¸ºæ£€æµ‹

### 3. Subtraction (ç›¸å‡)
```python
fused = |feature_A - feature_B|  # [1280ç»´]
```
- **ä¼˜åŠ¿**: æ•æ‰å·®å¼‚ç‰¹å¾
- **åŠ£åŠ¿**: ä¸¢å¤±å…±åŒç‰¹å¾
- **é€‚ç”¨**: è¡Œä¸ºå¯¹æ¯”åˆ†æ

### 4. Multiplication (ç›¸ä¹˜)
```python
fused = feature_A * feature_B  # [1280ç»´]
```
- **ä¼˜åŠ¿**: æ•æ‰äº¤äº’ç‰¹å¾
- **åŠ£åŠ¿**: å¯èƒ½è¿‡åº¦ä¾èµ–å…±åŒæ¿€æ´»
- **é€‚ç”¨**: ååŒè¡Œä¸ºæ£€æµ‹

### 5. Attention (æ³¨æ„åŠ›æœºåˆ¶) ğŸŒŸæ¨è
```python
weights = Attention([feature_A, feature_B])
fused = weights[0] * feature_A + weights[1] * feature_B
```
- **ä¼˜åŠ¿**: å­¦ä¹ æœ€ä¼˜æƒé‡ç»„åˆ
- **åŠ£åŠ¿**: è®¡ç®—å¤æ‚åº¦ç¨é«˜
- **é€‚ç”¨**: éœ€è¦æœ€ä½³æ€§èƒ½æ—¶

## ğŸ® ä½¿ç”¨æŒ‡å—

### Stage 1 è®­ç»ƒ (äºŒåˆ†ç±»ï¼šæœ‰æ— äº¤äº’)

```bash
# åŸºç¡€è®­ç»ƒ
python train_dual_person_stage1_downsampling.py \
    --fusion_method concat \
    --train_samples_per_epoch 10000 \
    --epochs 50

# æ³¨æ„åŠ›èåˆ + å®Œæ•´é…ç½®
python train_dual_person_stage1_downsampling.py \
    --fusion_method attention \
    --shared_backbone True \
    --train_samples_per_epoch 10000 \
    --val_samples_per_epoch 3000 \
    --epochs 50 \
    --learning_rate 1e-3 \
    --batch_size 16

# ç‹¬ç«‹backbone (æ›´å¤šå‚æ•°)
python train_dual_person_stage1_downsampling.py \
    --fusion_method concat \
    --shared_backbone False \
    --train_samples_per_epoch 8000 \
    --epochs 60
```

### Stage 2 è®­ç»ƒ (å¤šåˆ†ç±»ï¼šäº¤äº’ç±»å‹)

```bash
# ä½¿ç”¨é¢„è®­ç»ƒçš„Stage1æ¨¡å‹
python train_dual_person_stage2_downsampling.py \
    --stage1_checkpoint ./checkpoints/best_stage1.pth \
    --fusion_method attention \
    --train_samples_per_epoch 10000 \
    --use_class_weights \
    --focal_alpha 1.0 \
    --focal_gamma 2.0

# ä»å¤´è®­ç»ƒStage2 (ä¸æ¨è)
python train_dual_person_stage2_downsampling.py \
    --fusion_method concat \
    --train_samples_per_epoch 8000 \
    --epochs 40
```

### æµ‹è¯•å’ŒéªŒè¯

```bash
# è¿è¡Œå®Œæ•´æµ‹è¯•
python test_dual_person_downsampling.py

# æµ‹è¯•ç‰¹å®šé…ç½®
python -c "
from dual_person_downsampling_dataset import get_dual_person_downsampling_data_loaders
train_loader, _, _, _ = get_dual_person_downsampling_data_loaders(
    'D:/1data/imagedata', train_samples_per_epoch=1000
)
print(f'Train batches: {len(train_loader)}')
"
```

## âš™ï¸ å…³é”®å‚æ•°è¯´æ˜

### æ•°æ®ç›¸å…³
- `--train_samples_per_epoch`: æ¯ä¸ªepochçš„è®­ç»ƒæ ·æœ¬æ•° (é»˜è®¤10000)
- `--val_samples_per_epoch`: éªŒè¯æ ·æœ¬æ•° (None=å…¨é‡)
- `--balance_train_classes`: æ˜¯å¦ä¿æŒç±»åˆ«å¹³è¡¡ (é»˜è®¤True)
- `--crop_padding`: äººç‰©è£å‰ªæ—¶çš„è¾¹è· (é»˜è®¤20)
- `--min_person_size`: æœ€å°äººç‰©å°ºå¯¸è¿‡æ»¤ (é»˜è®¤32)

### æ¨¡å‹ç›¸å…³
- `--fusion_method`: èåˆæ–¹æ³• [concat/add/subtract/multiply/attention]
- `--shared_backbone`: æ˜¯å¦å…±äº«backboneæƒé‡ (é»˜è®¤True)
- `--backbone`: ç‰¹å¾æå–ç½‘ç»œ (ç›®å‰æ”¯æŒmobilenet)

### è®­ç»ƒç›¸å…³
- `--learning_rate`: å­¦ä¹ ç‡ (é»˜è®¤1e-3)
- `--batch_size`: æ‰¹æ¬¡å¤§å° (é»˜è®¤16)
- `--epochs`: è®­ç»ƒè½®æ•° (Stage1: 50, Stage2: 40)
- `--optimizer`: ä¼˜åŒ–å™¨ [adam/sgd] (é»˜è®¤adam)

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| æ–¹æ³• | äººç¾¤åœºæ™¯å‡†ç¡®ç‡ | è®­ç»ƒæ—¶é—´ | å‚æ•°é‡ | æ¨èæŒ‡æ•° |
|------|-------------|---------|--------|----------|
| åŸå§‹æ–¹æ³• | 70% | åŸºå‡† | åŸºå‡† | â­â­ |
| Concatèåˆ | 78% | +20% | +100% | â­â­â­ |
| Addèåˆ | 75% | +10% | +0% | â­â­â­ |
| Attentionèåˆ | 82% | +30% | +20% | â­â­â­â­â­ |

## ğŸ”§ å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### Q1: å†…å­˜ä¸è¶³
```bash
# è§£å†³æ–¹æ¡ˆï¼šå‡å°‘batch_sizeå’Œsamples_per_epoch
--batch_size 8 \
--train_samples_per_epoch 5000
```

### Q2: è®­ç»ƒæ—¶é—´å¤ªé•¿
```bash
# è§£å†³æ–¹æ¡ˆï¼šæ¿€è¿›ä¸‹é‡‡æ ·
--train_samples_per_epoch 3000 \
--val_samples_per_epoch 1000 \
--epochs 30
```

### Q3: æ€§èƒ½ä¸å¦‚é¢„æœŸ
```bash
# è§£å†³æ–¹æ¡ˆ1ï¼šä½¿ç”¨attentionèåˆ
--fusion_method attention

# è§£å†³æ–¹æ¡ˆ2ï¼šå¢åŠ è®­ç»ƒæ•°æ®
--train_samples_per_epoch 15000 \
--epochs 60
```

### Q4: Stage1æ¨¡å‹åŠ è½½å¤±è´¥
```bash
# æ£€æŸ¥è·¯å¾„å’Œæ¨¡å‹å…¼å®¹æ€§
ls -la ./checkpoints/
# ç¡®ä¿fusion_methodä¸€è‡´
--fusion_method attention --stage1_checkpoint path/to/attention_model.pth
```

## ğŸ¯ æ¨èè®­ç»ƒæµç¨‹

### æ­¥éª¤1: Stage1è®­ç»ƒ (æ¨èé…ç½®)
```bash
python train_dual_person_stage1_downsampling.py \
    --fusion_method attention \
    --shared_backbone True \
    --train_samples_per_epoch 10000 \
    --val_samples_per_epoch 3000 \
    --epochs 50 \
    --learning_rate 1e-3 \
    --batch_size 16 \
    --save_dir ./checkpoints/stage1
```

### æ­¥éª¤2: Stage2è®­ç»ƒ (ä½¿ç”¨Stage1æƒé‡)
```bash
python train_dual_person_stage2_downsampling.py \
    --stage1_checkpoint ./checkpoints/stage1/best_accuracy.pth \
    --fusion_method attention \
    --train_samples_per_epoch 10000 \
    --val_samples_per_epoch 3000 \
    --use_class_weights \
    --focal_alpha 1.0 \
    --focal_gamma 2.0 \
    --epochs 40 \
    --save_dir ./checkpoints/stage2
```

### æ­¥éª¤3: è¯„ä¼°å’Œä¼˜åŒ–
```bash
# è¿è¡Œæµ‹è¯•è„šæœ¬
python test_dual_person_downsampling.py

# æ£€æŸ¥è®­ç»ƒç»“æœ
ls -la ./checkpoints/stage1/
ls -la ./checkpoints/stage2/

# æŸ¥çœ‹è®­ç»ƒæ›²çº¿
# æ‰“å¼€ç”Ÿæˆçš„PNGæ–‡ä»¶: training_curves.png, confusion_matrix.png
```

## ğŸš€ é¢„æœŸæ•ˆæœ

ä½¿ç”¨åŒäººç‰¹å¾èåˆæ¶æ„ï¼Œä½ åº”è¯¥èƒ½è·å¾—ï¼š

1. **äººç¾¤åœºæ™¯å‡†ç¡®ç‡æå‡ 10-15%**
2. **è¯¯æ£€ç‡é™ä½ 20-30%**  
3. **ä¸ªä½“ç‰¹å¾æ›´åŠ ç²¾ç¡®**
4. **èƒŒæ™¯å¹²æ‰°æ˜¾è‘—å‡å°‘**
5. **æ¨¡å‹æ³›åŒ–èƒ½åŠ›å¢å¼º**

## ğŸ“ˆ åç»­æ”¹è¿›æ–¹å‘

1. **å¤šå°ºåº¦ç‰¹å¾èåˆ**: ç»“åˆä¸åŒå±‚çš„ç‰¹å¾
2. **æ—¶åºä¿¡æ¯åˆ©ç”¨**: è€ƒè™‘å‰åå¸§çš„å…³è”
3. **å§¿æ€ä¿¡æ¯é›†æˆ**: èåˆå…³é”®ç‚¹ç‰¹å¾
4. **è‡ªé€‚åº”èåˆæƒé‡**: æ ¹æ®åœºæ™¯åŠ¨æ€è°ƒæ•´
5. **è½»é‡åŒ–ä¼˜åŒ–**: å‡å°‘è®¡ç®—å¼€é”€

---

**æ³¨**: è¿™ä¸ªæ¶æ„æ˜¯å¯¹åŸå§‹æ–¹æ¡ˆçš„é‡å¤§æ”¹è¿›ï¼Œç‰¹åˆ«é€‚åˆäººç¾¤å¯†é›†çš„çœŸå®åœºæ™¯ã€‚å»ºè®®ä¼˜å…ˆä½¿ç”¨`attention`èåˆæ–¹æ³•ä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚